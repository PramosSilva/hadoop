{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de dados - Spark\n",
    "\n",
    "**Objetivo:** Realizar o pré-processamento do dataset Movielens utilizando a linguagem de programação pyspark.\n",
    "\n",
    "**Etapas a serem desenvolvidas:**\n",
    "\n",
    "**1.** Utilizar o Dataset recomendação.csv disponibilizado no canvas: <br/>\n",
    "    Schema: user_id int, item_id int, rating int, item string\n",
    "\n",
    "**2. ==CANCELADA==** Utilizar a ferramenta pydeequ (Links para um site externo.) para verificar se todos os dados se enquadram no schema definido acima. <br/>\n",
    "    Imprimir o Data Quality Report gerado pela ferramenta. <br/>\n",
    "    OBS: Para executar a ferramenta <br/>\n",
    "    Fazer download do deequ-1.0.5.jar e salvar na pasta que será executado o pyspark <br/>\n",
    "    Links para um site externo. <br/>\n",
    "    Instalar o pydeequ via pip ou pelo git. <br/>\n",
    "    Rodar o comando pyspark --driver-class-path deequ-1.0.5.jar **==CANCELADA==** <br/>\n",
    "\n",
    "**3.** Remover do Dataset os dados incorretos.\n",
    "\n",
    "**4.** Responder as perguntas: <br/>\n",
    "**4.1.** Qual o filme mais assistido? <br/>\n",
    "**4.2.** Qual o usuário que mais pontuou os filmes? <br/>\n",
    "**4.3.** Quantos usuários deram nota(rating) = 5? <br/>\n",
    "**4.4.** Agrupe o Dataset por user e some todas as suas notas. Qual o usuário possui a maior soma dos rating?\n",
    "\n",
    "**5.** Gerar Dataset tratado para o algoritmo de recomendação no formato csv com o schema user_id, item_id, rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Bibliotecas\n",
    "from pyspark.sql.types import StructType, IntegerType, DateType, StringType,StructField, FloatType\n",
    "from pyspark.sql.functions import col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Utilizar o Dataset recomendação.csv disponibilizado no canvas: <br/> Schema: user_id int, item_id int, rating int, item string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField('user_id', IntegerType()),\n",
    "                     StructField('item_id', IntegerType()),\n",
    "                     StructField('rating', IntegerType()),\n",
    "                     StructField('item', StringType()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando Dataset\n",
    "data = spark.read \\\n",
    "        .schema(schema)\\\n",
    "        .format(\"csv\")\\\n",
    "        .option(\"header\",True)\\\n",
    "        .load(\"recomendacao.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+--------------------+\n",
      "|user_id|item_id|rating|                item|\n",
      "+-------+-------+------+--------------------+\n",
      "|    186|    302|     3|L.A. Confidential...|\n",
      "|     22|    377|     1| Heavyweights (1994)|\n",
      "|    244|     51|     2|Legends of the Fa...|\n",
      "|    166|    346|     1| Jackie Brown (1997)|\n",
      "|    298|    474|     4|Dr. Strangelove o...|\n",
      "+-------+-------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+------------------+-----------------+------------------+--------------------+\n",
      "|summary|           user_id|          item_id|            rating|                item|\n",
      "+-------+------------------+-----------------+------------------+--------------------+\n",
      "|  count|             99999|            99999|             99999|               99547|\n",
      "|   mean| 462.4874148741487|425.5319653196532|3.5298652986529864|                null|\n",
      "| stddev|266.61442141060337|330.7995012117287| 1.125677980540639|                null|\n",
      "|    min|                 1|                1|                 1|'Til There Was Yo...|\n",
      "|    25%|               254|              175|                 3|                null|\n",
      "|    50%|               447|              322|                 4|                null|\n",
      "|    75%|               682|              631|                 4|                null|\n",
      "|    max|               943|             1682|                 5|Á köldum klaka (C...|\n",
      "+-------+------------------+-----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exibindo dataset e summary\n",
    "data.show(5)\n",
    "data.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, user_id: string, item_id: string, rating: string, item: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Remover do Dataset os dados incorretos. <br/> Não foi possível utilizar a erramenta pydeequ. <br/> Removendo os dados nulos de cada coluna.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.where(col(\"user_id\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.where(col(\"item_id\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.where(col(\"rating\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.where(col(\"item\").isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados após limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+--------------------+\n",
      "|user_id|item_id|rating|                item|\n",
      "+-------+-------+------+--------------------+\n",
      "|    186|    302|     3|L.A. Confidential...|\n",
      "|     22|    377|     1| Heavyweights (1994)|\n",
      "|    244|     51|     2|Legends of the Fa...|\n",
      "|    166|    346|     1| Jackie Brown (1997)|\n",
      "|    298|    474|     4|Dr. Strangelove o...|\n",
      "+-------+-------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+-----------------+------------------+------------------+--------------------+\n",
      "|summary|          user_id|           item_id|            rating|                item|\n",
      "+-------+-----------------+------------------+------------------+--------------------+\n",
      "|  count|            99547|             99547|             99547|               99547|\n",
      "|   mean|462.4214692557284| 427.4595819060343|3.5282831225451297|                null|\n",
      "| stddev| 266.581647089376|330.30761865180295|1.1262548341580603|                null|\n",
      "|    min|                1|                 2|                 1|'Til There Was Yo...|\n",
      "|    25%|              254|               176|                 3|                null|\n",
      "|    50%|              447|               323|                 4|                null|\n",
      "|    75%|              682|               633|                 4|                null|\n",
      "|    max|              943|              1682|                 5|Á köldum klaka (C...|\n",
      "+-------+-----------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)\n",
    "data.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Criação de view para usar o sql.\n",
    "data.createOrReplaceTempView('viewdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+--------------------+\n",
      "|user_id|item_id|rating|                item|\n",
      "+-------+-------+------+--------------------+\n",
      "|    186|    302|     3|L.A. Confidential...|\n",
      "|     22|    377|     1| Heavyweights (1994)|\n",
      "|    244|     51|     2|Legends of the Fa...|\n",
      "|    166|    346|     1| Jackie Brown (1997)|\n",
      "|    298|    474|     4|Dr. Strangelove o...|\n",
      "+-------+-------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mostrando 05 primeiras linhas da view criada.\n",
    "spark.sql('select * from viewdata').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Responder as perguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1) Qual o filme mais assistido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------+\n",
      "|item_id|                item|qtd_assistido|\n",
      "+-------+--------------------+-------------+\n",
      "|     50|    Star Wars (1977)|          583|\n",
      "|    258|      Contact (1997)|          509|\n",
      "|    100|        Fargo (1996)|          508|\n",
      "|    181|Return of the Jed...|          507|\n",
      "|    294|    Liar Liar (1997)|          485|\n",
      "|    286|English Patient, ...|          481|\n",
      "|    288|       Scream (1996)|          478|\n",
      "|    300|Air Force One (1997)|          431|\n",
      "|    121|Independence Day ...|          429|\n",
      "|    174|Raiders of the Lo...|          420|\n",
      "+-------+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verificação da quantidade de vezes que cada filme foi assistido em ordem decrescente. Exibindo os 10 mais.\n",
    "\n",
    "spark.sql('select item_id , item , count(item) as qtd_assistido \\\n",
    "          from viewdata \\\n",
    "          group by item_id, item \\\n",
    "          order by qtd_assistido desc').show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+-------------+\n",
      "|Filme_Mais_Assistido|ID |qtd_assistido|\n",
      "+--------------------+---+-------------+\n",
      "|Star Wars (1977)    |50 |583          |\n",
      "+--------------------+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Retorno do Filme mais assistido\n",
    "spark.sql('select * \\\n",
    "            from (select item as Filme_Mais_Assistido, item_id as ID, count(item_id) as qtd_assistido \\\n",
    "                  from viewdata \\\n",
    "                  group by ID, Filme_Mais_Assistido) viewdata \\\n",
    "            where qtd_assistido== \\\n",
    "                (select max(contador) \\\n",
    "                 from (select count(item_id) as contador\\\n",
    "                       from viewdata \\\n",
    "                       group by item_id ) viewdata) ').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2)Qual o usuário que mais pontuou os filmes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|ID_Usuario|qtd_votos|\n",
      "+----------+---------+\n",
      "|       405|      737|\n",
      "|       655|      684|\n",
      "|        13|      635|\n",
      "|       450|      539|\n",
      "|       276|      517|\n",
      "|       416|      492|\n",
      "|       537|      489|\n",
      "|       303|      483|\n",
      "|       234|      479|\n",
      "|       393|      447|\n",
      "+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verificação da quantidade de votos dos usuários em ordem decrescente. Exibindo os 10 que mais pontuaram os filmes\n",
    "\n",
    "spark.sql('select user_id as ID_Usuario , count(user_id) as qtd_votos \\\n",
    "          from viewdata \\\n",
    "          group by ID_Usuario \\\n",
    "          order by qtd_votos desc').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------+\n",
      "|ID_Usuario_Mais_Pontuou|Total_Voto|\n",
      "+-----------------------+----------+\n",
      "|405                    |737       |\n",
      "+-----------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Retorno do usuário que mais pontuou\n",
    "spark.sql('select * \\\n",
    "            from (select user_id as ID_Usuario_Mais_Pontuou, count(user_id) as Total_Voto \\\n",
    "                  from viewdata \\\n",
    "                  group by ID_Usuario_Mais_Pontuou) viewdata \\\n",
    "            where Total_Voto== \\\n",
    "                (select max(contador) \\\n",
    "                 from (select count(user_id) as contador\\\n",
    "                       from viewdata \\\n",
    "                       group by user_id ) viewdata) ').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3) Quantos usuários deram nota(rating) = 5? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "|ID_Usuario|Nota|\n",
      "+----------+----+\n",
      "|1         |5   |\n",
      "|2         |5   |\n",
      "|3         |5   |\n",
      "|4         |5   |\n",
      "|5         |5   |\n",
      "|6         |5   |\n",
      "|7         |5   |\n",
      "|8         |5   |\n",
      "|9         |5   |\n",
      "|10        |5   |\n",
      "+----------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Retornar os 10 primeiros usuários que deram nota 5 em ordem decrescente\n",
    "spark.sql('select distinct (user_id) as ID_Usuario, rating as Nota \\\n",
    "           from viewdata \\\n",
    "           where rating == \"5\" \\\n",
    "           order by ID_Usuario').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------------+\n",
      "|Nota|Qtde_Usuarios_que_deram_essa_nota|\n",
      "+----+---------------------------------+\n",
      "|5   |927                              |\n",
      "+----+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Retorno de quantidade de usuários que deram nota 5\n",
    "spark.sql('select rating as Nota, count(*) as Qtde_Usuarios_que_deram_essa_nota \\\n",
    "            from (select distinct (user_id), rating \\\n",
    "                   from viewdata \\\n",
    "                   where rating == \"5\") \\\n",
    "            group by rating').show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4) Agrupe o Dataset por user e some todas as suas notas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+--------------------------------------------------------+\n",
      "|ID_Usuario|Notas_atribuidas|Filme                                                   |\n",
      "+----------+----------------+--------------------------------------------------------+\n",
      "|19        |4               |Get Shorty (1995)                                       |\n",
      "|19        |5               |Butch Cassidy and the Sundance Kid (1969)               |\n",
      "|19        |3               |Stand by Me (1986)                                      |\n",
      "|19        |4               |Fish Called Wanda, A (1988)                             |\n",
      "|19        |2               |Titanic (1997)                                          |\n",
      "|19        |4               |Rainmaker, The (1997)                                   |\n",
      "|19        |3               |American President, The (1995)                          |\n",
      "|19        |3               |Adventures of Priscilla, Queen of the Desert, The (1994)|\n",
      "|19        |3               |Evil Dead II (1987)                                     |\n",
      "|19        |4               |Contact (1997)                                          |\n",
      "|19        |4               |Everyone Says I Love You (1996)                         |\n",
      "|19        |3               |Scream (1996)                                           |\n",
      "|19        |4               |Eve's Bayou (1997)                                      |\n",
      "|19        |4               |M*A*S*H (1970)                                          |\n",
      "|19        |3               |Indiana Jones and the Last Crusade (1989)               |\n",
      "|19        |2               |Chasing Amy (1997)                                      |\n",
      "|19        |4               |Crash (1996)                                            |\n",
      "|19        |4               |Groundhog Day (1993)                                    |\n",
      "|19        |5               |Babe (1995)                                             |\n",
      "|19        |3               |Liar Liar (1997)                                        |\n",
      "+----------+----------------+--------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#conferindo notas atribuída a filmes por usuário\n",
    "\n",
    "spark.sql('select user_id as ID_Usuario, rating as Notas_atribuidas, item as Filme \\\n",
    "           from viewdata \\\n",
    "           where user_id == \"19\" ').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|ID_Usuario|Soma_Notas|\n",
      "+----------+----------+\n",
      "|         1|       977|\n",
      "|         2|       226|\n",
      "|         3|       151|\n",
      "|         4|       104|\n",
      "|         5|       499|\n",
      "|         6|       763|\n",
      "|         7|      1598|\n",
      "|         8|       224|\n",
      "|         9|        94|\n",
      "|        10|       770|\n",
      "|        11|       627|\n",
      "|        12|       224|\n",
      "|        13|      1967|\n",
      "|        14|       401|\n",
      "|        15|       298|\n",
      "|        16|       601|\n",
      "|        17|        81|\n",
      "|        18|      1070|\n",
      "|        19|        71|\n",
      "|        20|       146|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Retorno da soma das notas dos 20 primeiros usuários\n",
    "\n",
    "spark.sql('select user_id as ID_Usuario , sum(rating) as Soma_Notas \\\n",
    "          from viewdata \\\n",
    "          group by ID_Usuario \\\n",
    "          order by ID_Usuario asc').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5) Qual o usuário possui a maior soma dos rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|ID_Usuario|Nota_maxima|\n",
      "+----------+-----------+\n",
      "|450       |2083       |\n",
      "|655       |1990       |\n",
      "|13        |1967       |\n",
      "+----------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Validando as 3 maiores somas das notas em ordem decrescente\n",
    "spark.sql('select user_id as ID_Usuario , sum(rating) as Nota_maxima \\\n",
    "            from viewdata \\\n",
    "            group by ID_Usuario order by Nota_maxima desc').show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Total rating\n",
       "user_id              \n",
       "450              2083"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retorno do usuário com maior soma de nota\n",
    "user_max = data.groupBy('user_id').sum('rating').sort('sum(rating)', ascending=False)\n",
    "user_max.limit(1).toPandas().set_index('user_id').rename(columns={'sum(rating)':'Total rating'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Gerar Dataset tratado para o algoritmo de recomendação no formato csv com o schema user_id, item_id, rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existe varios meios de exportar, neste trabalho foi selecionado um deles.\n",
    "data[['user_id', 'item_id', 'rating']].toPandas().to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conferindo dataset gerado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "        .schema(schema)\\\n",
    "        .format(\"csv\")\\\n",
    "        .option(\"header\",True)\\\n",
    "        .load(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
